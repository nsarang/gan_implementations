{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python [conda env:chollet]",
      "language": "python",
      "name": "conda-env-chollet-py"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-22T12:44:51.184520Z",
          "start_time": "2019-05-22T12:44:51.181798Z"
        },
        "heading_collapsed": true,
        "id": "TfbHlhVFXFsY",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZpEPLW0trlR",
        "colab_type": "code",
        "outputId": "69af1b97-c540-4710-8252-3ee931d9e8cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Google Colab setup\n",
        "\n",
        "GIT = True\n",
        "GIT_URL = 'https://github.com/nsarang/dcgan_mnist.git'\n",
        "GDRIVE = False\n",
        "GDRIVE_PWD = None\n",
        "\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    import os\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    \n",
        "if IN_COLAB:\n",
        "    if GIT:\n",
        "        !git clone {GIT_URL}\n",
        "        pwd = GIT_URL.split('/')[-1][:-4]\n",
        "        os.chdir(pwd)\n",
        "\n",
        "    elif GDRIVE:\n",
        "        drive.mount('/content/gdrive', force_remount=True)\n",
        "        root_dir = \"/content/gdrive/My Drive/\"\n",
        "        base_dir = os.path.join(root_dir, GDRIVE_PWD)\n",
        "        if not os.path.exists(base_dir):\n",
        "            os.makedirs(base_dir)\n",
        "        os.chdir(base_dir)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dcgan_mnist'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 7030 (delta 2), reused 1 (delta 0), pack-reused 7024\u001b[K\n",
            "Receiving objects: 100% (7030/7030), 235.69 MiB | 34.23 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Checking out files: 100% (7009/7009), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-sVqf5qzOXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "P_SAVE = 'saved_images'\n",
        "P_VIZ = 'visualization'\n",
        "\n",
        "dirs = [P_SAVE, P_VIZ]\n",
        "\n",
        "for d in dirs:\n",
        "    if not os.path.exists(d):\n",
        "        os.makedirs(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMRd6sWDXFsZ",
        "colab_type": "code",
        "outputId": "f14562ec-2add-45ba-c8f3-1f6f0e08038d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import keras.backend as K\n",
        "import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Qv8yBU4IXFse",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUsJHmnXzfVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 32\n",
        "height = 28\n",
        "width = 28\n",
        "channels = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-22T12:39:35.834063Z",
          "start_time": "2019-05-22T12:39:35.826571Z"
        },
        "hidden": true,
        "id": "JQnHqzkhXFse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "    gen_input = layers.Input(shape=(latent_dim,))\n",
        "    \n",
        "    # Transform the input into a 16 × 16 64-channel feature map\n",
        "    x = layers.Dense(64 * 14 * 14)(gen_input)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Reshape((14, 14, 64))(x)\n",
        "    \n",
        "    x = layers.Conv2D(64, 5, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Conv2D(128, 5, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Conv2D(128, 5, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    \n",
        "    # Upsample to 28 × 28\n",
        "    x = layers.Conv2DTranspose(128, 4, strides=2, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    \n",
        "    x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Conv2D(512, 5, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    \n",
        "    gen_out = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "    return models.Model(gen_input, gen_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-22T12:39:36.249063Z",
          "start_time": "2019-05-22T12:39:36.113326Z"
        },
        "hidden": true,
        "id": "g-qieldHXFsg",
        "colab_type": "code",
        "outputId": "14b752a9-ef67-454f-b607-db7e61d8204e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "build_generator().summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12544)             413952    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        102464    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 128)       204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 512)       3277312   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 1)         25089     \n",
            "=================================================================\n",
            "Total params: 5,515,201\n",
            "Trainable params: 5,515,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-22T12:43:53.400637Z",
          "start_time": "2019-05-22T12:43:53.393673Z"
        },
        "hidden": true,
        "id": "TWyp6fDTXFsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator():\n",
        "    disc_input = layers.Input(shape=(height, width, channels))\n",
        "    \n",
        "    x = layers.Conv2D(64, 3)(disc_input)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Conv2D(128, 4, padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    \n",
        "    x = layers.Conv2D(256, 4, strides=2)(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Conv2D(256, 4, strides=2)(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    \n",
        "    # One dropout layer: an important trick!\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    \n",
        "    # Classification layer\n",
        "    disc_out = layers.Dense(1, activation='sigmoid')(x)\n",
        "    return models.Model(disc_input, disc_out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-22T12:43:53.736854Z",
          "start_time": "2019-05-22T12:43:53.609190Z"
        },
        "hidden": true,
        "id": "N2nhXgtUXFsn",
        "colab_type": "code",
        "outputId": "512a5bd1-2b8e-498f-e4ef-1674d28e8ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "build_discriminator().summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 12, 12, 128)       131200    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 12, 12, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 5, 5, 256)         524544    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 1, 1, 256)         1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 1,967,745\n",
            "Trainable params: 1,967,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pq73Y7aXFsp",
        "colab_type": "text"
      },
      "source": [
        "## Build GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-22T13:27:56.600548Z",
          "start_time": "2019-05-22T13:27:30.391Z"
        },
        "id": "AquMJrLBXFsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gan(g_lr, d_lr):\n",
        "    generator = build_generator()\n",
        "    discriminator = build_discriminator() \n",
        "\n",
        "    discriminator_optimizer = keras.optimizers.RMSprop(\n",
        "        lr=d_lr,\n",
        "        clipvalue=1.0, # Uses gradient clipping (by value) in the optimizer\n",
        "        decay=1e-8) # To stabilize training, uses learning-rate decay\n",
        "\n",
        "    discriminator.compile(optimizer=discriminator_optimizer,\n",
        "                          loss='binary_crossentropy')\n",
        "    \n",
        "    # Sets discriminator weights to non-trainable (this will only apply to the gan model)\n",
        "    discriminator.trbainable = False\n",
        "\n",
        "    gan_input = layers.Input(shape=(latent_dim,))\n",
        "    gan_output = discriminator(generator(gan_input))\n",
        "    gan = models.Model(gan_input, gan_output)\n",
        "\n",
        "    gan_optimizer = keras.optimizers.RMSprop(lr=g_lr, clipvalue=1.0, decay=1e-8)\n",
        "    gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
        "    \n",
        "    return generator, discriminator, gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6ZaUETEXFsu",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-22T13:27:56.611135Z",
          "start_time": "2019-05-22T13:27:31.720Z"
        },
        "id": "BFXQvpdiXFsw",
        "colab_type": "code",
        "outputId": "49647cb6-b345-4460-f527-a09c6ce6b639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "# Normalize data to [-1, 1]\n",
        "x_train = x_train.reshape((x_train.shape[0],) + (height, width, channels))\n",
        "x_train = x_train.astype('float32') / 127.5  - 1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIIYjETJIxGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def combine_images(generated_images):\n",
        "    total,width,height = generated_images.shape[:-1]\n",
        "    rows = int(math.sqrt(total))\n",
        "    cols = math.ceil(total / rows)\n",
        "    combined_image = np.zeros((height*rows, width*cols),\n",
        "                              dtype=generated_images.dtype)\n",
        "\n",
        "    for index, image in enumerate(generated_images):\n",
        "        i = index // cols\n",
        "        j = index % cols\n",
        "        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[:, :, 0]\n",
        "    return combined_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-22T13:27:56.616930Z",
          "start_time": "2019-05-22T13:27:33.001Z"
        },
        "id": "fmNi3Q1kXFs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from skimage.transform import rescale\n",
        "\n",
        "\n",
        "iterations = 15000\n",
        "batch_size = 35\n",
        "\n",
        "generator, discriminator, gan = build_gan(0.00008, 0.0002)\n",
        "\n",
        "\n",
        "noise_num = 3\n",
        "random_noises = np.random.normal(size=(noise_num, batch_size, latent_dim))\n",
        "\n",
        "\n",
        "# Start training loop\n",
        "start = 0\n",
        "\n",
        "for step in range(iterations):\n",
        "    # Sample random points in the latent space\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "    # Decode them to fake images\n",
        "    generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "    # Combine them with real images\n",
        "    stop = start + batch_size\n",
        "    real_images = x_train[start: stop]\n",
        "    combined_images = np.concatenate([generated_images, real_images])\n",
        "\n",
        "    # Assemble labels discriminating real from fake images\n",
        "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
        "                             np.zeros((batch_size, 1))])\n",
        "    \n",
        "    # Add random noise to the labels - important trick!\n",
        "    labels += 0.05 * np.random.random(labels.shape)\n",
        "\n",
        "    # Train the discriminator\n",
        "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "    # sample random points in the latent space\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "    # Assemble labels that say \"all real images\"\n",
        "    misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "    # Train the generator (via the gan model,\n",
        "    # where the discriminator weights are frozen)\n",
        "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "    \n",
        "    start += batch_size\n",
        "    if start > len(x_train) - batch_size:\n",
        "        start = 0\n",
        "\n",
        "    # Occasionally save / plot\n",
        "    if step % 50 == 0:\n",
        "        \n",
        "        # Print metrics\n",
        "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
        "        print('adversarial loss at step %s: %s' % (step, a_loss))\n",
        "\n",
        "        \n",
        "        for i in range(noise_num):\n",
        "            img = combine_images(generator.predict(random_noises[i]))\n",
        "            plt.imsave(P_SAVE + f'/generated_from_noise{i}_step{step}.png',\n",
        "                       img,\n",
        "                       cmap='gray',\n",
        "                       vmin=-1,\n",
        "                       vmax=1)\n",
        "\n",
        "                \n",
        "        plt.figure(figsize=(6, 7.5))\n",
        "        plt.axis('off')\n",
        "        plt.imshow(combine_images(generated_images), cmap='gray', vmin=-1, vmax=1)\n",
        "        plt.show()\n",
        "        \n",
        "\n",
        "# Save model weights\n",
        "gan.save_weights('gan.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r105Sjx_MBd",
        "colab_type": "text"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qg2u57L_TCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "import glob\n",
        "\n",
        "for i in range(noise_num):\n",
        "    files = sorted(glob.glob(f'{P_SAVE}/*noise{i}*.png'),\n",
        "                   key=lambda x: (len(x), x))\n",
        "    \n",
        "    frames = [imageio.imread(f) for i,f in enumerate(files) if i % 10 == 0]\n",
        "    imageio.mimsave(f'{P_VIZ}/viz{i+1}.gif', frames, duration=0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsE37kMrfLVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('visualization/viz1.gif') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM1N_pIY_AnT",
        "colab_type": "text"
      },
      "source": [
        "## Version Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt9cvZgr81YB",
        "colab_type": "text"
      },
      "source": [
        "**This section is mainly used when working from Google Colaboratory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKUfG7eR8E8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git config user.email \"nimasarang@gmail.com\"\n",
        "!git config user.name \"nsarang\"\n",
        "!git remote set-url origin https://nsarang:****@github.com/nsarang/dcgan_mnist.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVVgUDdwLewV",
        "colab_type": "code",
        "outputId": "07deb963-9562-4072-d1fb-8f566059aafd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!du -hs saved_images"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55M\tsaved_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KaBTRvVyAJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git status"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFnJHFOLyF3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git add -A\n",
        "!git commit -m \"clean up\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzUqhPTP7qsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git push"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
